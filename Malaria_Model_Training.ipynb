{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ü¶† Malaria Cell Detection ‚Äî Train & Export to TF.js\n",
        "**By Scott Antwi**\n\n",
        "This notebook trains a CNN on the NIH Malaria Dataset and converts it to TensorFlow.js for the web app.\n\n",
        "‚ö° **Make sure GPU is enabled:** Runtime ‚Üí Change runtime type ‚Üí T4 GPU"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Install Dependencies"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs -q\n",
        "print('‚úÖ Ready')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Download Dataset"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Download the NIH Malaria dataset\n",
        "!wget -q https://data.lhncbc.nlm.nih.gov/public/Malaria/cell_images.zip\n",
        "!unzip -q cell_images.zip -d dataset\n",
        "\n",
        "# Find the data path\n",
        "DATA_PATH = None\n",
        "for root, dirs, files in os.walk('dataset/'):\n",
        "    if 'Parasitized' in dirs:\n",
        "        DATA_PATH = root + '/'\n",
        "        break\n",
        "\n",
        "print(f'üìÇ Data path: {DATA_PATH}')\n",
        "print(f'üìä Parasitized: {len(os.listdir(DATA_PATH + \"Parasitized\"))} images')\n",
        "print(f'üìä Uninfected: {len(os.listdir(DATA_PATH + \"Uninfected\"))} images')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Load & Preprocess Images"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "IMG_SIZE = 64\n",
        "\n",
        "def load_images(folder, label):\n",
        "    images, labels = [], []\n",
        "    for filename in os.listdir(folder):\n",
        "        try:\n",
        "            img = Image.open(os.path.join(folder, filename))\n",
        "            img = img.resize((IMG_SIZE, IMG_SIZE))\n",
        "            images.append(np.array(img))\n",
        "            labels.append(label)\n",
        "        except:\n",
        "            pass\n",
        "    return images, labels\n",
        "\n",
        "print('Loading infected cells...')\n",
        "X_infected, y_infected = load_images(DATA_PATH + 'Parasitized/', 1)\n",
        "print(f'  ‚úÖ {len(X_infected)} infected images')\n",
        "\n",
        "print('Loading healthy cells...')\n",
        "X_healthy, y_healthy = load_images(DATA_PATH + 'Uninfected/', 0)\n",
        "print(f'  ‚úÖ {len(X_healthy)} healthy images')\n",
        "\n",
        "# Combine and normalize\n",
        "X = np.array(X_infected + X_healthy, dtype='float32') / 255.0\n",
        "y = np.array(y_infected + y_healthy)\n",
        "\n",
        "del X_infected, X_healthy, y_infected, y_healthy\n",
        "\n",
        "print(f'\\nüìä Total: {len(X)} images')\n",
        "print(f'üìä Infected: {sum(y)} | Healthy: {len(y) - sum(y)}')\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "print(f'\\nüîÄ Train: {len(X_train)} | Test: {len(X_test)}')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Build & Train CNN"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "model = models.Sequential([\n",
        "    # Block 1\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Block 2\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Block 3\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Classification head\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "print('\\nüöÄ Training...')\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_split=0.15,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'\\nüéØ Test Accuracy: {round(accuracy * 100, 2)}%')\n",
        "print(f'üìâ Test Loss: {round(loss, 4)}')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Convert to TensorFlow.js"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflowjs as tfjs\n",
        "import shutil\n",
        "\n",
        "# Convert model\n",
        "tfjs.converters.save_keras_model(model, 'tfjs_model')\n",
        "print('‚úÖ Model converted to TF.js format')\n",
        "\n",
        "# Show output files\n",
        "print('\\nüìÅ Output files:')\n",
        "for f in os.listdir('tfjs_model'):\n",
        "    size = os.path.getsize(f'tfjs_model/{f}') / 1024\n",
        "    print(f'  {f} ({size:.1f} KB)')\n",
        "\n",
        "# Zip for download\n",
        "shutil.make_archive('tfjs_model', 'zip', 'tfjs_model')\n",
        "print('\\nüì¶ Zipped and ready to download!')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Download the Model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('tfjs_model.zip')\n",
        "print('\\nüéâ Done! Send this zip to Little Alpha and the web app will work with real predictions!')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}